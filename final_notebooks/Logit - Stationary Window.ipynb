{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7myE7HTSw-BW"
   },
   "source": [
    "## Initialize and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25362,
     "status": "ok",
     "timestamp": 1565926102086,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "rKudAsaQR0al",
    "outputId": "e416099e-f999-43ad-98a5-81757cffd3e7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, Flatten\n",
    "from tensorflow.keras.utils import normalize\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from google.colab import drive\n",
    "import os \n",
    "import pprint\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#np.random.seed(7)\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaOKC30uR0an"
   },
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        \n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkjhecuTtq93"
   },
   "source": [
    "## Load Data from Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4hq9RI9PyQ2"
   },
   "outputs": [],
   "source": [
    "chass_monthly_file_location = os.path.join(\"/content/gdrive/My Drive/1977monthly.csv\")\n",
    "data_extract_monthly = pd.read_csv(chass_monthly_file_location)\n",
    "data_extract_monthly['datadate'] =  pd.to_datetime(data_extract_monthly['datadate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9q_IA_YmYte1"
   },
   "source": [
    "#### Constituent Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiNbnTzxtk1c"
   },
   "outputs": [],
   "source": [
    "tsx_constituents_file_location = os.path.join(\"/content/gdrive/My Drive/constituents_tsx.csv\")\n",
    "tsx_constituents = pd.read_csv(tsx_constituents_file_location)\n",
    "tsx_constituents['from'] =  pd.to_datetime(tsx_constituents['from'], format='%m/%d/%Y')\n",
    "tsx_constituents['thru'] =  pd.to_datetime(tsx_constituents['thru'], format='%m/%d/%Y')\n",
    "tsx_constituents =tsx_constituents[tsx_constituents['conm'] == 'S&P/TSX Composite Index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6ax56WbxIYW"
   },
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MH_RJTIQIS6e"
   },
   "source": [
    "### Map S&P TSX Composite Constituents and Create Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaA2S8DHtesK"
   },
   "source": [
    "#### Monthly Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIRm0BuNtcYR"
   },
   "outputs": [],
   "source": [
    "temp1 = data_extract_monthly[data_extract_monthly['cusip'].isin(tsx_constituents['co_cusip'])]\n",
    "temp2 = data_extract_monthly[data_extract_monthly['ticker'].isin(tsx_constituents['co_tic'])]\n",
    "temp3 = pd.concat([temp1,temp2]).drop_duplicates().reset_index()\n",
    "temp3['prc_mret']=temp3['prc_mret'].fillna(0)\n",
    "temp = temp3[['ticker','datadate','prc_mret']].sort_values(['ticker','datadate','prc_mret']).set_index('datadate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tdtiz56KmimU"
   },
   "outputs": [],
   "source": [
    "J = 12\n",
    "temp['logret']=np.log(1+temp['prc_mret'])\n",
    "umd = temp.groupby(['ticker'])['logret'].rolling(J, min_periods=J).sum()\n",
    "umd = umd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1k39u5VnWUGH"
   },
   "outputs": [],
   "source": [
    "umd['cumret']=np.exp(umd['logret'])-1\n",
    "umd = umd.dropna(axis=0, subset=['cumret'])\n",
    "umd = umd.reset_index()\n",
    "umd = umd[umd['datadate'] >= '1982-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1565926199666,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "ixhko5PWqgv6",
    "outputId": "8b0b4c30-2909-4934-f19b-45370f5bd471"
   },
   "outputs": [],
   "source": [
    "umd[umd['ticker'] == 'BCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3Ufo6lTWvz_"
   },
   "outputs": [],
   "source": [
    "temp_monthly = umd.pivot_table(index='datadate', columns='ticker', values='cumret')\n",
    "temp_monthly = temp_monthly.fillna(0)\n",
    "stock_list_monthly = temp_monthly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3833,
     "status": "ok",
     "timestamp": 1565833614657,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "UWreJI9BuIQZ",
    "outputId": "48af9415-8996-4653-ce0b-9f08097f83e4"
   },
   "outputs": [],
   "source": [
    "len(stock_list_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOZYM0hQIp4p"
   },
   "source": [
    "### Create Time Series Constituents Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twkpKX2Y4pL2"
   },
   "source": [
    "#### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1565926247660,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "Rj0tLBdjumnC",
    "outputId": "d7b4b86a-0467-41cf-c447-3f44c848de08"
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "total = len(temp_monthly.columns)\n",
    "constituents_monthly = pd.DataFrame(index=temp_monthly.index)\n",
    "for stock in stock_list_monthly:\n",
    "    stock_cusip = temp3[temp3['ticker'] == stock]['cusip'].unique()[0]\n",
    "    \n",
    "    stock_dates_from = tsx_constituents[tsx_constituents['co_cusip'] == stock_cusip]['from']\n",
    "    if len(stock_dates_from.values) == 0:\n",
    "        stock_dates_from = tsx_constituents[tsx_constituents['co_tic'] == stock]['from']\n",
    "    stock_dates_thru = tsx_constituents[tsx_constituents['co_cusip'] == stock_cusip]['thru']\n",
    "    if len(stock_dates_thru.values) == 0:\n",
    "        stock_dates_thru = tsx_constituents[tsx_constituents['co_tic'] == stock]['thru']\n",
    "    \n",
    "    stock_dates_thru = stock_dates_thru.fillna(pd.to_datetime('today'))\n",
    "    \n",
    "    for i in range(0,len(stock_dates_from)):\n",
    "        constituents_monthly[stock] = np.where(\n",
    "            (temp_monthly.index >= pd.to_datetime(stock_dates_from.values[i]).strftime('%Y-%m-%d')) \n",
    "            & (temp_monthly.index <= pd.to_datetime(stock_dates_thru.values[i]).strftime('%Y-%m-%d')), 1, 0)\n",
    "        \n",
    "    k=k+1\n",
    "    update_progress(k/total)\n",
    "    \n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhK2rMemIa9W"
   },
   "source": [
    "### Calculate Mean And Create Training Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxNP2gdt4kid"
   },
   "source": [
    "#### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkYCgF1_WIVE"
   },
   "outputs": [],
   "source": [
    "dataset_monthly = temp_monthly.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGVCWZ9Xrcry"
   },
   "outputs": [],
   "source": [
    "median = (dataset_monthly*constituents_monthly).median(axis=1)\n",
    "mean = (dataset_monthly*constituents_monthly).mean(axis=1)\n",
    "std = (dataset_monthly*constituents_monthly).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1565926271639,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "z7VzVXAZuNCv",
    "outputId": "5c25b166-75bb-4b5b-e923-3d9f03ed50fe"
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "for c in stock_list_monthly:\n",
    "    #label based on value relative to crosssectional median\n",
    "    temp = np.where(dataset_monthly[c] >= median, 0, 1)\n",
    "    dataset_monthly[c + '_out'] = np.append(temp[1:len(temp)],[0])\n",
    "    k=k+1\n",
    "    update_progress(k/ len(stock_list_monthly))\n",
    "\n",
    "dataset_monthly = dataset_monthly.fillna(0)\n",
    "dataset_monthly['median'] = median\n",
    "dataset_monthly['mean'] = mean\n",
    "dataset_monthly['std'] = std\n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdgfBtkfIwuF"
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyXImoMG4ubS"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HdOFSbUR0bI"
   },
   "outputs": [],
   "source": [
    "train_size = .9\n",
    "month_offset = 12\n",
    "num_of_years = 20\n",
    "look_back = 12\n",
    "daily_length = 20\n",
    "step = 1\n",
    "study_period = look_back * num_of_years\n",
    "num_of_rows, num_of_columns = dataset_monthly.shape\n",
    "num_of_iterations = int(num_of_rows/6) - look_back - month_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYVFVsde5T9-"
   },
   "source": [
    "### Input/Output Preparation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yk-ZdKhbcukw"
   },
   "source": [
    "#### Monthly Only Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3C6kkz1OzDG"
   },
   "outputs": [],
   "source": [
    "def data_prep(look_back,step,column_subset,trainset):\n",
    "  X_s = np.empty((0,))\n",
    "  y_s = np.empty((0))\n",
    "    \n",
    "  #k=0\n",
    "  \n",
    "  for stock in column_subset:\n",
    "    timeseries = np.asarray(trainset[stock],dtype=np.float32)\n",
    "    X = timeseries\n",
    "    y_series = np.asarray(trainset[stock + '_out'])\n",
    "    y = y_series\n",
    "    test = len(X) -len(y)\n",
    "    if test > 0:\n",
    "      print(stock)\n",
    "    X_s = np.append(X_s, X, axis=0)\n",
    "    y_s = np.append(y_s, y, axis=0)\n",
    "        \n",
    "  X_in = X_s.astype(np.float32)\n",
    "  y_in = y_s.astype(np.int32)\n",
    "  return(X_in,y_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQlPslAVcz-9"
   },
   "source": [
    "#### Merge Monthly with Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkjCGwScyCHi"
   },
   "outputs": [],
   "source": [
    "def data_prep(look_back,step,column_subset,trainset):\n",
    "  X_s = np.empty((0, look_back+daily_length, step))\n",
    "  y_s = np.empty((0, 2))\n",
    "  x_daily = np.array([])\n",
    "  y_daily = np.array([])\n",
    "  X_out = np.empty(shape=(daily_length-1,look_back+daily_length,1))\n",
    "\n",
    "  for stock in column_subset:\n",
    "    \n",
    "    #normalize trainset data \n",
    "    #trainset[stock] = (trainset[stock] - trainset[stock][:int(len(trainset))].mean())/trainset[stock][:int(len(trainset))].std()\n",
    "    \n",
    "    for i in range(daily_length-1):\n",
    "      month_end_index = dataset_daily.index.get_loc(dataset_daily[dataset_daily.index == trainset[stock][(i+look_back+1):(i+1+look_back+1)].index[0].strftime('%Y-%m-%d')].index[0])\n",
    "      lookback_index = month_end_index - daily_length\n",
    "      x_daily = np.append(x_daily,np.asarray(dataset_daily.iloc[lookback_index:month_end_index][stock],dtype=np.float32))\n",
    "\n",
    "    timeseries = np.asarray(trainset[stock],dtype=np.float32)\n",
    "    x_daily = np.atleast_2d(x_daily)\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "\n",
    "    if timeseries.shape[0] == 1:\n",
    "      timeseries = timeseries.T\n",
    "\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + look_back] for start in range(0, timeseries.shape[0] - look_back)]))\n",
    "    \n",
    "\n",
    "    if x_daily.shape[0] == 1:\n",
    "      x_daily = x_daily.T\n",
    "\n",
    "    y_series = np.asarray(trainset[stock + '_out'])\n",
    "    y = y_series[look_back:len(y_series)-1]\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    for i in range(daily_length-1):\n",
    "      X_out[i] = np.concatenate((X[i],x_daily[(i*daily_length):((i*daily_length)+daily_length)]), axis=0)\n",
    "      \n",
    "    X_s = np.append(X_s, X_out, axis=0)\n",
    "    y_s = np.append(y_s, y, axis=0)\n",
    "\n",
    "  X_in = X_s.astype(np.float32)\n",
    "  y_in = y_s.astype(np.int32)\n",
    "  return(normalize(X_in),y_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxs4Y3QM5Y9M"
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 443,
     "status": "error",
     "timestamp": 1565926279265,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "Fwm1k8ryR0bK",
    "outputId": "5d2381ba-da0e-4431-f1d9-737b1a5a8ba8"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "num_of_iterations = 18\n",
    "while i < num_of_iterations:\n",
    "  \n",
    "    print(\"On Iteration \" + str(i) + \" of \" + str(num_of_iterations))\n",
    "  \n",
    "    datasubset = dataset_monthly[i*month_offset:(i*month_offset)+study_period].copy(deep=True)\n",
    "    trainset = datasubset[:int(len(datasubset) * train_size)].copy(deep=True)\n",
    "    testset = datasubset[int(len(datasubset) * train_size):].copy(deep=True)\n",
    "    \n",
    "    column_subset = constituents_monthly.loc[testset.index[len(testset.index)-13]]\n",
    "    column_subset = column_subset[column_subset == 1].index\n",
    "    \n",
    "    X_in,y_in = data_prep(look_back,step,column_subset,trainset)\n",
    "    clf = LogisticRegression(solver='lbfgs').fit(X_in.reshape(-1,1), y_in)\n",
    "    \n",
    "    s = 0\n",
    "\n",
    "    for c in column_subset:\n",
    "      testset[c + '_dn'] = 0.0000000\n",
    "      testset[c + '_up'] = 0.0000000\n",
    "      for k in range(len(testset.index)):\n",
    "            \n",
    "        if k >= look_back:\n",
    "          b = np.asarray(testset[c]).reshape(-1,1)\n",
    "          yp = clf.predict_proba(b)\n",
    "          testset.loc[testset.index[k], c + '_up'] = yp[0][0]\n",
    "          testset.loc[testset.index[k], c + '_dn'] = yp[0][1]\n",
    "          testset[c + '_out_pred'] = np.where(testset[c +'_up'] >= testset[c + '_dn'], 0, 1)\n",
    "          \n",
    "      s = s +1\n",
    "      update_progress(s/len(column_subset))\n",
    "          \n",
    "    result_file_name = \"/content/gdrive/My Drive/temp_out_logit1/\" + str(i) + \"results.csv\"\n",
    "    testset.to_csv(result_file_name)\n",
    "    \n",
    "    i = i + 1\n",
    "    update_progress(i / num_of_iterations)\n",
    "    del datasubset\n",
    "\n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwlfGyxrChF7"
   },
   "source": [
    "## Verification Code (corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ah_3Aq7nChF-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "results_extract = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joekvVmrChGC"
   },
   "outputs": [],
   "source": [
    "def prepare_output(id_vars, results_extract,dataset_monthly,i):\n",
    "  y_pred = np.array(0)\n",
    "  y_actual = np.array(0)\n",
    "  y_scores = np.array(0)\n",
    "\n",
    "  for stock in id_vars:\n",
    "    test = results_extract[results_extract['variable'] == stock].set_index('datadate').sort_index()\n",
    "    test2 = dataset_monthly[[stock +'_out']]\n",
    "    if len(test) >0:\n",
    "      min_date = min(test.index)\n",
    "      test2 = test2[test2.index >= min_date]\n",
    "      test2 = test2.iloc[:len(test)]\n",
    "      y_actual = np.append(y_actual, np.asarray(test2[stock +'_out']))\n",
    "      y_pred = np.append(y_pred, np.asarray(test['pred']))\n",
    "      #the dn variable ended up being the positive predictor\n",
    "      y_scores = np.append(y_scores, np.asarray(test['dn']))\n",
    "\n",
    "  tn, fp, fn, tp = confusion_matrix(y_actual, y_pred).ravel()\n",
    "  #since classes are reverse here with 0 being positive and 1 being negative\n",
    "  fpr, tpr, thresholds = metrics.roc_curve(y_actual, y_scores,pos_label=1)\n",
    "\n",
    "  plt.subplot(4, 5, i)\n",
    "  plt.plot([0, 1], [0, 1], 'k--')\n",
    "  plt.plot(fpr, tpr, label='LR')\n",
    "  plt.xlabel('False positive rate')\n",
    "  plt.ylabel('True positive rate')\n",
    "  plt.title('ROC curve for ' + min_date.split(sep='-')[0])\n",
    "  plt.legend(loc='best')\n",
    "  return (min_date.split(sep='-')[0],tn/(tn+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1565926403602,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "4T6zl0VLChGE",
    "outputId": "17bc4a12-2900-49a0-ea66-0168f8a4aa31"
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "i = 0\n",
    "iterations = 18\n",
    "j = 0\n",
    "time_frame = 12\n",
    "offset = 12\n",
    "plt.figure(figsize=(20,20))\n",
    "accuracy_df = pd.DataFrame()\n",
    "\n",
    "for i in range(j,iterations):\n",
    "  csv_name = os.path.join(\"/content/gdrive/My Drive/temp_out_logit1/\" + str(i) + \"results.csv\")\n",
    "  df = pd.read_csv(csv_name)\n",
    "  df = df[offset:]\n",
    "  print(df['datadate'])\n",
    "  id_vars = [x for x in df.columns if ('_ismember' not in x) \n",
    "             and ('_out' not in x) \n",
    "             and ('_dn' not in x) \n",
    "             and ('_up' not in x) \n",
    "             and ('mean' not in x)\n",
    "             and ('std' not in x)\n",
    "             and ('median' not in x)\n",
    "             and ('datadate' not in x)\n",
    "            ]\n",
    "  value_vars = [x for x in df.columns if ('_out' in x) or ('_dn' in x) ]\n",
    "\n",
    "  result = pd.DataFrame()\n",
    "  for stock in id_vars:\n",
    "    id_varss = ['datadate']\n",
    "    temp = [x for x in value_vars if (stock+'_dn') == x or (stock+'_out_pred'==x)]\n",
    "    if len(temp) >0:\n",
    "      id_varss = id_varss + temp\n",
    "      #print(id_varss)\n",
    "      temp = pd.melt(df, id_vars=id_varss, value_vars=[stock])\n",
    "      temp.rename(columns={stock+'_dn':'dn', stock+'_out_pred':'pred'}, inplace=True)\n",
    "      result = pd.concat([result,temp])\n",
    "\n",
    "  accuracy = prepare_output(id_vars,result,dataset_monthly,i+1)\n",
    "  print(accuracy)\n",
    "  temp_df = pd.DataFrame([[accuracy[0],accuracy[1]]],columns=['year','accuracy'])\n",
    "  accuracy_df = accuracy_df.append(temp_df)\n",
    "\n",
    "  k = k+1\n",
    "  update_progress(k/iterations)\n",
    "  #results_extract = pd.concat([results_extract,result])\n",
    "  #accuracy = prepare_output(id_vars,result,dataset_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101268,
     "status": "ok",
     "timestamp": 1565926403604,
     "user": {
      "displayName": "Rafik Matta",
      "photoUrl": "",
      "userId": "06643372443318823080"
     },
     "user_tz": 240
    },
    "id": "A6FGHTDEChGG",
    "outputId": "dbb7506f-8629-4dca-e96e-edc7a7be8204"
   },
   "outputs": [],
   "source": [
    "accuracy_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "GlBBV3yusvMX"
   ],
   "name": "Logit - Stationary Window.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
