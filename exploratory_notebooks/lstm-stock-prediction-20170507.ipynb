{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "179c2ccd-823a-9576-f8d4-552dbbde3483"
   },
   "source": [
    "# 25/04/2019 Update\n",
    "Please check out my  [new embedding model](https://www.kaggle.com/benjibb/entity-embedding-neural-network), which I think is more promising than the existing method.\n",
    "\n",
    "# 07/05/2017 Update\n",
    "\n",
    "This project is based on my [GitHub link][1] and my research is based on  [this paper][2]. \n",
    "\n",
    "Instead of using Echo state network which was used in the Stanford research paper, we are going to use LSTM which is more advanced in training the neural network.\n",
    "\n",
    "More updates will be provided to accommodate the dataset in this Kaggle challenge.  You can simply adjust it to choose your features and window for data.\n",
    "\n",
    "Thank you all!\n",
    "\n",
    "# Import module first\n",
    "\n",
    "\n",
    "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data\n",
    "  [2]: http://cs229.stanford.edu/proj2012/BernalFokPidaparthi-FinancialMarketTimeSeriesPredictionwithRecurrentNeural.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "78d1f84f-aed9-747b-154a-f7fe6c7bb8c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import h5py\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02cc6c64-3161-cf2d-4298-c700c2eee594"
   },
   "source": [
    "# Read data and transform them to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e10138dc-b1a1-fd9e-64c8-3bbf3b1844a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "      <td>125.839996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "      <td>119.980003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "      <td>114.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "      <td>116.620003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "      <td>114.970001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol        open     ...         volume   adj close\n",
       "date                              ...                           \n",
       "2016-01-05   WLTW  123.430000     ...      2163600.0  125.839996\n",
       "2016-01-06   WLTW  125.239998     ...      2386400.0  119.980003\n",
       "2016-01-07   WLTW  116.379997     ...      2489500.0  114.949997\n",
       "2016-01-08   WLTW  115.480003     ...      2006300.0  116.620003\n",
       "2016-01-11   WLTW  117.010002     ...      1408600.0  114.970001\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "83a2dfa1-a5e0-580f-1617-faa4b8e25ed3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Period Ending</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>Changes in Inventories</th>\n",
       "      <th>Common Stocks</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Deferred Asset Charges</th>\n",
       "      <th>Deferred Liability Charges</th>\n",
       "      <th>Depreciation</th>\n",
       "      <th>Earnings Before Interest and Tax</th>\n",
       "      <th>Earnings Before Tax</th>\n",
       "      <th>Effect of Exchange Rate</th>\n",
       "      <th>Equity Earnings/Loss Unconsolidated Subsidiary</th>\n",
       "      <th>Fixed Assets</th>\n",
       "      <th>Goodwill</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Income Tax</th>\n",
       "      <th>Intangible Assets</th>\n",
       "      <th>Interest Expense</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Investments</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>Long-Term Debt</th>\n",
       "      <th>Long-Term Investments</th>\n",
       "      <th>Minority Interest</th>\n",
       "      <th>Misc. Stocks</th>\n",
       "      <th>Net Borrowings</th>\n",
       "      <th>Net Cash Flow</th>\n",
       "      <th>Net Cash Flow-Operating</th>\n",
       "      <th>Net Cash Flows-Financing</th>\n",
       "      <th>Net Cash Flows-Investing</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Net Income Adjustments</th>\n",
       "      <th>Net Income Applicable to Common Shareholders</th>\n",
       "      <th>Net Income-Cont. Operations</th>\n",
       "      <th>Net Receivables</th>\n",
       "      <th>Non-Recurring Items</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Other Assets</th>\n",
       "      <th>Other Current Assets</th>\n",
       "      <th>Other Current Liabilities</th>\n",
       "      <th>Other Equity</th>\n",
       "      <th>Other Financing Activities</th>\n",
       "      <th>Other Investing Activities</th>\n",
       "      <th>Other Liabilities</th>\n",
       "      <th>Other Operating Activities</th>\n",
       "      <th>Other Operating Items</th>\n",
       "      <th>Pre-Tax Margin</th>\n",
       "      <th>Pre-Tax ROE</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Research and Development</th>\n",
       "      <th>Retained Earnings</th>\n",
       "      <th>Sale and Purchase of Stock</th>\n",
       "      <th>Sales, General and Admin.</th>\n",
       "      <th>Short-Term Debt / Current Portion of Long-Term Debt</th>\n",
       "      <th>Short-Term Investments</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.330000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127000000.0</td>\n",
       "      <td>1.049900e+10</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>223000000.0</td>\n",
       "      <td>1.001000e+09</td>\n",
       "      <td>-1.813000e+09</td>\n",
       "      <td>-2.445000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.340200e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.435600e+10</td>\n",
       "      <td>-5.690000e+08</td>\n",
       "      <td>8.690000e+08</td>\n",
       "      <td>632000000.0</td>\n",
       "      <td>5.800000e+08</td>\n",
       "      <td>3.060000e+08</td>\n",
       "      <td>4.730000e+08</td>\n",
       "      <td>7.116000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.020000e+09</td>\n",
       "      <td>197000000.0</td>\n",
       "      <td>1.285000e+09</td>\n",
       "      <td>4.830000e+08</td>\n",
       "      <td>-1.571000e+09</td>\n",
       "      <td>-1.876000e+09</td>\n",
       "      <td>2.050000e+09</td>\n",
       "      <td>-1.876000e+09</td>\n",
       "      <td>-4.084000e+09</td>\n",
       "      <td>1.124000e+09</td>\n",
       "      <td>3.860000e+08</td>\n",
       "      <td>1.480000e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.167000e+09</td>\n",
       "      <td>6.260000e+08</td>\n",
       "      <td>4.524000e+09</td>\n",
       "      <td>-2.980000e+09</td>\n",
       "      <td>1.509000e+09</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>1.514700e+10</td>\n",
       "      <td>-141000000.0</td>\n",
       "      <td>8.450000e+08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.462000e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.297700e+10</td>\n",
       "      <td>1.419000e+09</td>\n",
       "      <td>3.412000e+09</td>\n",
       "      <td>2.351000e+10</td>\n",
       "      <td>7.072000e+09</td>\n",
       "      <td>9.011000e+09</td>\n",
       "      <td>-7.987000e+09</td>\n",
       "      <td>2.489100e+10</td>\n",
       "      <td>1.690400e+10</td>\n",
       "      <td>2.485500e+10</td>\n",
       "      <td>-367000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>3.350000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.175000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>1.101900e+10</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>935000000.0</td>\n",
       "      <td>1.020000e+09</td>\n",
       "      <td>-1.324000e+09</td>\n",
       "      <td>-2.180000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.925900e+10</td>\n",
       "      <td>4.086000e+09</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.572400e+10</td>\n",
       "      <td>-3.460000e+08</td>\n",
       "      <td>2.311000e+09</td>\n",
       "      <td>856000000.0</td>\n",
       "      <td>1.012000e+09</td>\n",
       "      <td>-1.181000e+09</td>\n",
       "      <td>-2.350000e+08</td>\n",
       "      <td>1.535300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.208000e+09</td>\n",
       "      <td>660000000.0</td>\n",
       "      <td>6.750000e+08</td>\n",
       "      <td>3.799000e+09</td>\n",
       "      <td>-3.814000e+09</td>\n",
       "      <td>-1.834000e+09</td>\n",
       "      <td>1.873000e+09</td>\n",
       "      <td>-1.834000e+09</td>\n",
       "      <td>-4.489000e+09</td>\n",
       "      <td>1.560000e+09</td>\n",
       "      <td>5.590000e+08</td>\n",
       "      <td>1.399000e+09</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.299000e+09</td>\n",
       "      <td>1.465000e+09</td>\n",
       "      <td>7.385000e+09</td>\n",
       "      <td>-2.032000e+09</td>\n",
       "      <td>1.711000e+09</td>\n",
       "      <td>481000000.0</td>\n",
       "      <td>1.491500e+10</td>\n",
       "      <td>-56000000.0</td>\n",
       "      <td>8.530000e+08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.129600e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.291300e+10</td>\n",
       "      <td>1.446000e+09</td>\n",
       "      <td>8.111000e+09</td>\n",
       "      <td>4.227800e+10</td>\n",
       "      <td>1.432300e+10</td>\n",
       "      <td>1.380600e+10</td>\n",
       "      <td>-2.731000e+09</td>\n",
       "      <td>4.500900e+10</td>\n",
       "      <td>4.227800e+10</td>\n",
       "      <td>2.674300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>1.630222e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.768000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>1.562000e+10</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>829000000.0</td>\n",
       "      <td>1.342000e+09</td>\n",
       "      <td>4.099000e+09</td>\n",
       "      <td>3.212000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.308400e+10</td>\n",
       "      <td>4.091000e+09</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.703000e+10</td>\n",
       "      <td>3.300000e+08</td>\n",
       "      <td>2.240000e+09</td>\n",
       "      <td>887000000.0</td>\n",
       "      <td>1.004000e+09</td>\n",
       "      <td>1.799000e+09</td>\n",
       "      <td>-1.026000e+09</td>\n",
       "      <td>1.604300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.700000e+08</td>\n",
       "      <td>-146000000.0</td>\n",
       "      <td>3.080000e+09</td>\n",
       "      <td>-3.150000e+08</td>\n",
       "      <td>-2.911000e+09</td>\n",
       "      <td>2.882000e+09</td>\n",
       "      <td>5.420000e+08</td>\n",
       "      <td>2.882000e+09</td>\n",
       "      <td>2.882000e+09</td>\n",
       "      <td>1.771000e+09</td>\n",
       "      <td>8.000000e+08</td>\n",
       "      <td>4.249000e+09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.060000e+09</td>\n",
       "      <td>8.980000e+08</td>\n",
       "      <td>7.059000e+09</td>\n",
       "      <td>-4.559000e+09</td>\n",
       "      <td>8.170000e+08</td>\n",
       "      <td>601000000.0</td>\n",
       "      <td>1.092800e+10</td>\n",
       "      <td>-500000000.0</td>\n",
       "      <td>1.295000e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.562000e+09</td>\n",
       "      <td>-1.052000e+09</td>\n",
       "      <td>2.068600e+10</td>\n",
       "      <td>1.677000e+09</td>\n",
       "      <td>6.309000e+09</td>\n",
       "      <td>4.322500e+10</td>\n",
       "      <td>1.175000e+10</td>\n",
       "      <td>1.340400e+10</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>4.120400e+10</td>\n",
       "      <td>4.322500e+10</td>\n",
       "      <td>4.265000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.169154e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.085000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>1.109600e+10</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.477000e+09</td>\n",
       "      <td>667000000.0</td>\n",
       "      <td>1.487000e+09</td>\n",
       "      <td>5.496000e+09</td>\n",
       "      <td>4.616000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.751000e+10</td>\n",
       "      <td>4.091000e+09</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.989400e+10</td>\n",
       "      <td>-2.994000e+09</td>\n",
       "      <td>2.249000e+09</td>\n",
       "      <td>880000000.0</td>\n",
       "      <td>8.630000e+08</td>\n",
       "      <td>4.430000e+08</td>\n",
       "      <td>-6.330000e+08</td>\n",
       "      <td>1.833000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.856000e+09</td>\n",
       "      <td>-604000000.0</td>\n",
       "      <td>6.249000e+09</td>\n",
       "      <td>-1.259000e+09</td>\n",
       "      <td>-5.594000e+09</td>\n",
       "      <td>7.610000e+09</td>\n",
       "      <td>-2.662000e+09</td>\n",
       "      <td>7.610000e+09</td>\n",
       "      <td>7.610000e+09</td>\n",
       "      <td>1.425000e+09</td>\n",
       "      <td>1.051000e+09</td>\n",
       "      <td>6.204000e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.103000e+09</td>\n",
       "      <td>7.480000e+08</td>\n",
       "      <td>6.272000e+09</td>\n",
       "      <td>-4.732000e+09</td>\n",
       "      <td>9.600000e+07</td>\n",
       "      <td>114000000.0</td>\n",
       "      <td>1.017800e+10</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>1.364000e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.230000e+09</td>\n",
       "      <td>-3.846000e+09</td>\n",
       "      <td>2.127500e+10</td>\n",
       "      <td>2.231000e+09</td>\n",
       "      <td>5.864000e+09</td>\n",
       "      <td>4.841500e+10</td>\n",
       "      <td>9.985000e+09</td>\n",
       "      <td>1.360500e+10</td>\n",
       "      <td>5.635000e+09</td>\n",
       "      <td>4.278000e+10</td>\n",
       "      <td>4.841500e+10</td>\n",
       "      <td>4.099000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6.681299e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAP</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>2.409453e+09</td>\n",
       "      <td>-89482000.0</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.711820e+08</td>\n",
       "      <td>5.202150e+08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.981110e+08</td>\n",
       "      <td>-260298000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>3.106967e+09</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.895440e+08</td>\n",
       "      <td>6.579150e+08</td>\n",
       "      <td>6.240740e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.292547e+09</td>\n",
       "      <td>7.638900e+07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.098036e+09</td>\n",
       "      <td>2.364040e+08</td>\n",
       "      <td>2.884500e+07</td>\n",
       "      <td>33841000.0</td>\n",
       "      <td>2.308609e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.263230e+08</td>\n",
       "      <td>6.044610e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.774450e+08</td>\n",
       "      <td>540210000.0</td>\n",
       "      <td>6.852810e+08</td>\n",
       "      <td>1.279070e+08</td>\n",
       "      <td>-2.729780e+08</td>\n",
       "      <td>3.876700e+08</td>\n",
       "      <td>2.331100e+07</td>\n",
       "      <td>3.876700e+08</td>\n",
       "      <td>3.876700e+08</td>\n",
       "      <td>2.298660e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.573150e+08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.183300e+07</td>\n",
       "      <td>4.761400e+07</td>\n",
       "      <td>1.495580e+08</td>\n",
       "      <td>2.667000e+06</td>\n",
       "      <td>-3.349900e+07</td>\n",
       "      <td>-1796000.0</td>\n",
       "      <td>2.390210e+08</td>\n",
       "      <td>8213000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.149000e+08</td>\n",
       "      <td>-1.860000e+07</td>\n",
       "      <td>2.440721e+09</td>\n",
       "      <td>6.270000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.613814e+09</td>\n",
       "      <td>3.184200e+09</td>\n",
       "      <td>2.559638e+09</td>\n",
       "      <td>1.210694e+09</td>\n",
       "      <td>3.403120e+09</td>\n",
       "      <td>4.613814e+09</td>\n",
       "      <td>6.205003e+09</td>\n",
       "      <td>-27095000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>7.328355e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             ...              Estimated Shares Outstanding\n",
       "0           0             ...                              3.350000e+08\n",
       "1           1             ...                              1.630222e+08\n",
       "2           2             ...                              7.169154e+08\n",
       "3           3             ...                              6.681299e+08\n",
       "4           4             ...                              7.328355e+07\n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../input/fundamentals.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5a80f7c5-3ab2-5ac2-1b1e-26f9ecc53c34"
   },
   "source": [
    "# Extract all symbols from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8eab994d-dd03-6a73-0bbe-28c68ba58a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = list(set(df.symbol))\n",
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ca231b38-093b-2d84-d190-587f737c23d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMZN',\n",
       " 'DFS',\n",
       " 'WFM',\n",
       " 'DLR',\n",
       " 'KHC',\n",
       " 'AMT',\n",
       " 'NDAQ',\n",
       " 'BSX',\n",
       " 'GOOGL',\n",
       " 'FITB',\n",
       " 'AEP']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[:11] # Example of what is in symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83aeaa46-584e-beef-e8e6-a121a51c43d8"
   },
   "source": [
    "# Extract a particular price for stock in symbols\n",
    "Use GOOG as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "ca7ef19e-e4ce-c4b9-24ab-fd62a279f599"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>312.304948</td>\n",
       "      <td>310.955001</td>\n",
       "      <td>313.580158</td>\n",
       "      <td>3927000.0</td>\n",
       "      <td>312.205308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>312.419511</td>\n",
       "      <td>309.610028</td>\n",
       "      <td>312.748278</td>\n",
       "      <td>6031900.0</td>\n",
       "      <td>310.830459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>311.761979</td>\n",
       "      <td>302.048370</td>\n",
       "      <td>311.761979</td>\n",
       "      <td>7987100.0</td>\n",
       "      <td>302.994813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>303.562685</td>\n",
       "      <td>295.218951</td>\n",
       "      <td>303.861575</td>\n",
       "      <td>12876600.0</td>\n",
       "      <td>295.941242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>294.895159</td>\n",
       "      <td>293.455551</td>\n",
       "      <td>300.499172</td>\n",
       "      <td>9483900.0</td>\n",
       "      <td>299.886470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open         low     ...          volume   adj close\n",
       "date                                   ...                            \n",
       "2010-01-04  312.304948  310.955001     ...       3927000.0  312.205308\n",
       "2010-01-05  312.419511  309.610028     ...       6031900.0  310.830459\n",
       "2010-01-06  311.761979  302.048370     ...       7987100.0  302.994813\n",
       "2010-01-07  303.562685  295.218951     ...      12876600.0  295.941242\n",
       "2010-01-08  294.895159  293.455551     ...       9483900.0  299.886470\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.symbol == 'GOOG']\n",
    "df.drop(['symbol'],1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f9cab92-a31c-034a-df07-7bc7d6591668"
   },
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a6052d2e-f656-543b-90cc-9f85b9837bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.157047</td>\n",
       "      <td>0.161167</td>\n",
       "      <td>0.156390</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.159399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.157238</td>\n",
       "      <td>0.158884</td>\n",
       "      <td>0.154995</td>\n",
       "      <td>0.202469</td>\n",
       "      <td>0.157092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.156140</td>\n",
       "      <td>0.146049</td>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.268184</td>\n",
       "      <td>0.143942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.142436</td>\n",
       "      <td>0.134457</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.432522</td>\n",
       "      <td>0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0.127950</td>\n",
       "      <td>0.131464</td>\n",
       "      <td>0.134455</td>\n",
       "      <td>0.318492</td>\n",
       "      <td>0.138726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open       low      high    volume  adj close\n",
       "date                                                         \n",
       "2010-01-04  0.157047  0.161167  0.156390  0.131722   0.159399\n",
       "2010-01-05  0.157238  0.158884  0.154995  0.202469   0.157092\n",
       "2010-01-06  0.156140  0.146049  0.153341  0.268184   0.143942\n",
       "2010-01-07  0.142436  0.134457  0.140094  0.432522   0.132105\n",
       "2010-01-08  0.127950  0.131464  0.134455  0.318492   0.138726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
    "    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n",
    "    return df\n",
    "df = normalize_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cda2ae07-6030-3cfc-7786-8557891c0fb7"
   },
   "source": [
    "# Create training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "27bca4c4-cd5f-23a3-2e3f-53433cf2dd96"
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns) # 5\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features \n",
    "    \n",
    "    x_train = train[:, :-1] \n",
    "    y_train = train[:, -1][:,-1]\n",
    "    \n",
    "    x_test = result[int(row):, :-1] \n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9cbdcc33-fb39-0ee8-2604-d47c6d2e1b92"
   },
   "source": [
    "# Build the structure of model\n",
    "\n",
    "Based on my hyperparameter testing on [here][1]. I found that these parameters are the most suitable for this task.\n",
    "\n",
    "![dropout = 0.3][2]\n",
    "![epochs = 90][3]\n",
    "![LSTM 256 > LSTM 256 > Relu 32 > Linear 1][4]\n",
    "\n",
    "\n",
    "\n",
    "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data\n",
    "  [2]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/dropout.png?raw=true\n",
    "  [3]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/epochs2.png?raw=true\n",
    "  [4]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/neurons.png?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "17b0bf0c-5b76-9052-ecd3-b9f99ba3da94"
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    d = 0.3\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "    \n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "        \n",
    "    start = time.time()\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca28b9e0-390f-5368-b043-00d0fc4f1b2a"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "c3c292d2-bd7b-6e7f-bbba-39b64860ba20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15704696 0.16116746 0.15638998 0.1317225  0.15939908]\n",
      " [0.15723843 0.15888449 0.15499506 0.20246902 0.15709185]\n",
      " [0.15613951 0.14604929 0.15334121 0.26818406 0.14394234]\n",
      " [0.14243617 0.13445699 0.14009362 0.43252209 0.13210528]\n",
      " [0.12795029 0.13146379 0.13445546 0.3184921  0.13872603]\n",
      " [0.13832355 0.1356323  0.13546617 0.48640628 0.1379653 ]\n",
      " [0.13265404 0.13052526 0.13020388 0.3271972  0.12907917]\n",
      " [0.11503787 0.1186032  0.12203482 0.43807453 0.12624527]\n",
      " [0.12120685 0.12613696 0.12689613 0.2858228  0.12855249]\n",
      " [0.12906589 0.12210374 0.12636158 0.36641044 0.12031836]\n",
      " [0.11895908 0.12062405 0.12373877 0.29099208 0.12668832]\n",
      " [0.12293853 0.11977851 0.12003013 0.21906583 0.12066114]\n",
      " [0.12082392 0.1172081  0.12073176 0.42532947 0.1228095 ]\n",
      " [0.10505596 0.0855935  0.10718348 0.45857351 0.09524822]\n",
      " [0.09014547 0.08614311 0.08987641 0.29795279 0.08688037]\n",
      " [0.08296912 0.08680264 0.08964255 0.29361033 0.08890336]\n",
      " [0.08571648 0.08597403 0.08801372 0.26721945 0.08863587]\n",
      " [0.08839717 0.08199153 0.08747078 0.21760714 0.08210705]\n",
      " [0.08340204 0.0777723  0.08245074 0.27910072 0.07847068]\n",
      " [0.08016357 0.08173786 0.07812399 0.15159969 0.0810454 ]\n",
      " [0.08046326 0.07946339 0.07741402 0.27611276 0.07945711]\n",
      " [0.07522667 0.07998762 0.08337794 0.20208586 0.08756581]] 0.07582908201368749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "window = 22\n",
    "X_train, y_train, X_test, y_test = load_data(df, window)\n",
    "print (X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "212f77cd-fdeb-40df-595b-d6de775610f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Compilation Time :  0.038523197174072266\n"
     ]
    }
   ],
   "source": [
    "model = build_model([5,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "886256b4-7578-d3a5-6cf0-ae394e3339ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1408 samples, validate on 157 samples\n",
      "Epoch 1/90\n",
      "1408/1408 [==============================] - 4s 3ms/step - loss: 0.1276 - acc: 7.1023e-04 - val_loss: 0.5037 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0602 - acc: 7.1023e-04 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0329 - acc: 7.1023e-04 - val_loss: 0.1290 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0158 - acc: 7.1023e-04 - val_loss: 0.1902 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0158 - acc: 7.1023e-04 - val_loss: 0.0880 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0067 - acc: 7.1023e-04 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0073 - acc: 7.1023e-04 - val_loss: 0.0538 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 7.1023e-04 - val_loss: 0.0709 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0047 - acc: 7.1023e-04 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0033 - acc: 7.1023e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 7.1023e-04 - val_loss: 0.0421 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0025 - acc: 7.1023e-04 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0023 - acc: 7.1023e-04 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 7.1023e-04 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0019 - acc: 7.1023e-04 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 7.1023e-04 - val_loss: 0.0438 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 7.1023e-04 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 7.1023e-04 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0015 - acc: 7.1023e-04 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0014 - acc: 7.1023e-04 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 7.1023e-04 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0012 - acc: 7.1023e-04 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0011 - acc: 7.1023e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.7868e-04 - acc: 7.1023e-04 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.3987e-04 - acc: 7.1023e-04 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.6569e-04 - acc: 7.1023e-04 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.7750e-04 - acc: 7.1023e-04 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.8758e-04 - acc: 7.1023e-04 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 0.0010 - acc: 7.1023e-04 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.4205e-04 - acc: 7.1023e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.2784e-04 - acc: 7.1023e-04 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.8207e-04 - acc: 7.1023e-04 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.3833e-04 - acc: 7.1023e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.9338e-04 - acc: 7.1023e-04 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.4135e-04 - acc: 7.1023e-04 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.7402e-04 - acc: 7.1023e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.7360e-04 - acc: 7.1023e-04 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.1533e-04 - acc: 7.1023e-04 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.4600e-04 - acc: 7.1023e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.8224e-04 - acc: 7.1023e-04 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.9048e-04 - acc: 7.1023e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.6166e-04 - acc: 7.1023e-04 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.9822e-04 - acc: 7.1023e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.7886e-04 - acc: 7.1023e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.7790e-04 - acc: 7.1023e-04 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.4410e-04 - acc: 7.1023e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.9646e-04 - acc: 7.1023e-04 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.5115e-04 - acc: 7.1023e-04 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 9.0487e-04 - acc: 7.1023e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.2505e-04 - acc: 7.1023e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.7024e-04 - acc: 7.1023e-04 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "1408/1408 [==============================] - 2s 2ms/step - loss: 8.5393e-04 - acc: 7.1023e-04 - val_loss: 0.0059 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99cd30d828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "52177800-ffc4-dfd5-c915-46d98f941ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "print (p.shape)\n",
    "# for each data index in test data\n",
    "for u in range(len(y_test)):\n",
    "    # pr = prediction day u\n",
    "    pr = p[u][0]\n",
    "    # (y_test day u / pr) - 1\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
    "    # Last day prediction\n",
    "    # print(p[-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc1b3c69-d033-e7c1-9ff3-04cefd5d9940"
   },
   "source": [
    "# Denormalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "fb935328-2516-89a0-e555-bdc5b289dac9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df = df[df.symbol == 'GOOG']\n",
    "df.drop(['symbol'],1,inplace=True)\n",
    "\n",
    "# Bug fixed at here, please update the denormalize function to this one\n",
    "def denormalize(df, normalized_value): \n",
    "    df = df['adj close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(df, p)\n",
    "newy_test = denormalize(df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "2f638a96-8f36-7dc9-4118-f97e3df06705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00109 MSE (0.03 RMSE)\n",
      "Test Score: 0.00938 MSE (0.10 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0010917398363006667, 0.009376307392771217)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "335d3b00-b700-a97f-c2ad-938949618ac7"
   },
   "source": [
    "# Since the Kaggle dataset only contains a few years, the mean square error is not as small as my original model on GitHub.\n",
    "\n",
    "With more than 40 years of data, we will get:\n",
    "\n",
    "Train Score: 0.00006 MSE (0.01 RMSE)\n",
    "\n",
    "Test Score: 0.00029 MSE (0.02 RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "99be25aa-e2c3-35fd-64a5-988200295018"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(newp,color='red', label='Prediction')\n",
    "plt2.plot(newy_test,color='blue', label='Actual')\n",
    "plt2.legend(loc='best')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a4f7f8a2-0f0a-495c-23c5-adf40fcd8c39"
   },
   "source": [
    "The result on my original model with more than 40 years of data.\n",
    "\n",
    "![Result][1]\n",
    "\n",
    " Train Score: 0.00006 MSE (0.01 RMSE)\n",
    "\n",
    "Test Score: 0.00029 MSE (0.02 RMSE)\n",
    "\n",
    "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/raw/master/result2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "485cfea1-9204-92b6-3cc3-2c98f8f3138d"
   },
   "source": [
    "# Thank you all for reading\n",
    " If you have any question or concern, please leave a comment. Otherwise, see you next time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "a20d18af-b200-167b-8498-1e4450ac0cd6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "e2ff8e71-c6c2-8be6-3f09-ccd7ce6060c1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "a7a89691-1dbc-8eca-c83f-8d791f101aff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "fb075e10-f271-b6df-4be0-214ae0092fb7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "5bbce8a2-3ef4-ac9a-6fa0-bec57c86a64b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b5eb2379-45c6-54e9-252d-5cd7ea150b9f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "73092acc-eb54-aeb8-6616-8b1f16b0569d",
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "9b09a45c-0595-bc94-2ca6-d6930181b109"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "16fb7e45-13e5-7fd6-dd63-2b18f0fdac30"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce0ba2d6-3f74-c2da-3363-d46d38fcdc77"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "6e18acc0-de77-7a74-a857-bedf2c19d9fe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "14d5f557-3767-7a6e-1992-d8a9ff78ee87"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "c9bf36cd-1c14-e608-103d-05ec02f6f68f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "bac5d910-ca0d-0e21-4f88-a8c9365dfa9b",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
